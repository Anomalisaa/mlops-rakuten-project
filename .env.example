# CREDENTIAL CONFIG

DAGSHUB_USER_NAME=actual_user_name
DAGSHUB_USER_TOKEN=token
DAGSHUB_REPO_OWNER=BeritM
DAGSHUB_REPO_NAME=mlops-rakuten-project

#GITHUB_EMAIL=email_address
GITHUB_USER_NAME=actual_user_name
GITHUB_TOKEN=token
GITHUB_REPO_OWNER=BeritM
GITHUB_REPO_NAME=mlops-rakuten-project

# PATH CONFIG
# directories
DATA_RAW_DIR = "/app/shared_volume/data/raw"
DATA_PROCESSED_DIR = "/app/shared_volume/data/processed"
DATA_FEEDBACK_DIR = "/app/shared_volume/data/feedback"
MODEL_DIR = "/app/shared_volume/models"

#raw
X_RAW = "X_train_update.csv"
Y_RAW = "Y_train_CVw08PX.csv"
X_Y_RAW = "raw_x_y.csv"

# processed
X_TRAIN_TFIDF = "X_train_tfidf.pkl"
X_VALIDATE_TFIDF = "X_validate_tfidf.pkl"
X_TEST_TFIDF = "X_test_tfidf.pkl"

Y_TRAIN = "y_train.pkl"
Y_VALIDATE = "y_validate.pkl"
Y_TEST = "y_test.pkl"

# models
TFIDF_VECTORIZER = "tfidf_vectorizer.pkl"
MODEL = "sgd_text_model.pkl"
PRODUCT_DICTIONARY = "product_dictionary.pkl"
CLASS_REPORT = "training_class_report.txt"
CURRENT_RUN_ID = "current_run_id.txt"

# model_training
PARAM_CONFIG = "param_config.yml"

# feedback
FEEDBACK_CSV = "feedback.csv"


# AIRFLOW
# Airflow User ID (für Linux/Mac: $(id -u), für Windows: 50000)
AIRFLOW_UID=50000

# Airflow Admin Credentials
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow

# Airflow Fernet Key (for encrytion of Connections/Variables)
# Can be generated: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
#AIRFLOW__CORE__FERNET_KEY= <Key>

# Optional: Email for Alerts
#AIRFLOW__SMTP__SMTP_HOST=smtp.gmail.com
#AIRFLOW__SMTP__SMTP_USER=your-email@gmail.com
#AIRFLOW__SMTP__SMTP_PASSWORD=your-app-password
#AIRFLOW__SMTP__SMTP_PORT=587
#AIRFLOW__SMTP__SMTP_MAIL_FROM=your-email@gmail.com